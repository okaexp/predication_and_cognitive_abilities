dplyr::filter(PickedSample == 1) %>%
dplyr::select(order, trial_index, word_pair, answer, point_oka, point_ksm, comment_oka, Note_ksm)
nrow(dat_calc_reliablity)
dat_calc_reliablity <- dat_calc_reliablity %>%
dplyr::mutate(Classification_ksm = as.factor(point_ksm),
Classification_oka = as.factor(point_oka)) %>%
dplyr::mutate(ageement = if_else(
Classification_ksm == Classification_oka, 1, 0
)
)
# クロス表の作成
cross_tab_dat <- dat_calc_reliablity %>% group_by(Classification_ksm, Classification_oka) %>%
tally %>%
spread(Classification_oka, n)
cross_tab_dat
#分類一致率の算出
dat_concat_kappa <- dat_calc_reliablity[,c("Classification_ksm", "Classification_oka")]
kappa2(dat_concat_kappa,weight = TRUE)
irr::agree(dat_concat_kappa)
irr::kappam.fleiss(dat_concat_kappa, detail = TRUE)
#追記: ICC算出のために書き起こす
dat_calc_reliablity_icc <- raw_dat %>%
dplyr::filter(PickedSample == 1) %>%
dplyr::select(order, trial_index, word_pair, answer, point_oka, point_ksm, comment_oka, Note_ksm)
dat_calc_reliablity_icc <- dat_calc_reliablity_icc[,c("point_ksm", "point_oka")]
irr::icc(dat_calc_reliablity_icc, model="twoway", type="agreement", unit="average")
# 抽出したデータを吐き出す
openxlsx::write.xlsx(raw_dat, "../../3_edited_dat_after_aggregate/data/20230516_edited_dat_aggregated_v0.1.xlsx")
#最終更新: 2023年5月16日 16:47
library(tidyr)
library(dplyr)
library(lme4)
library(lmerTest)
library(ggplot2)
library(stringr)
library(irr)
library(openxlsx)
#参加者のデータの読み込み
#シート「Sheet 1」の内容
raw_dat <- read.xlsx("../result/20230503_pick_and_classifying_samples_26_percents_format_kusumi.xlsx", sheet = "Sheet 1")
#dat
dat_calc_reliablity <- raw_dat %>%
dplyr::filter(PickedSample == 1) %>%
dplyr::select(order, trial_index, word_pair, answer, point_oka, point_ksm, comment_oka, Note_ksm)
dat_calc_reliablity <- dat_calc_reliablity %>%
dplyr::mutate(Classification_ksm = as.factor(point_ksm),
Classification_oka = as.factor(point_oka)) %>%
dplyr::mutate(ageement = if_else(
Classification_ksm == Classification_oka, 1, 0
)
)
# クロス表の作成
cross_tab_dat <- dat_calc_reliablity %>% group_by(Classification_ksm, Classification_oka) %>%
tally %>%
spread(Classification_oka, n)
#分類一致率の算出
dat_concat_kappa <- dat_calc_reliablity[,c("Classification_ksm", "Classification_oka")]
kappa2(dat_concat_kappa,weight = TRUE)
irr::agree(dat_concat_kappa)
irr::kappam.fleiss(dat_concat_kappa, detail = TRUE)
#追記: ICC算出のために書き起こす
dat_calc_reliablity_icc <- raw_dat %>%
dplyr::filter(PickedSample == 1) %>%
dplyr::select(order, trial_index, word_pair, answer, point_oka, point_ksm, comment_oka, Note_ksm)
dat_calc_reliablity_icc <- dat_calc_reliablity_icc[,c("point_ksm", "point_oka")]
irr::icc(dat_calc_reliablity_icc, model="twoway", type="agreement", unit="average")
#最終更新: 2023年5月16日 16:47
library(tidyr)
library(dplyr)
library(lme4)
library(lmerTest)
library(ggplot2)
library(stringr)
library(irr)
library(openxlsx)
#参加者のデータの読み込み
#シート「Sheet 1」の内容
raw_dat <- read.xlsx("../result/20230503_pick_and_classifying_samples_26_percents_format_kusumi.xlsx", sheet = "Sheet 1")
#dat
dat_calc_reliablity <- raw_dat %>%
dplyr::filter(PickedSample == 1) %>%
dplyr::select(order, trial_index, word_pair, answer, point_oka, point_ksm, comment_oka, Note_ksm)
dat_calc_reliablity <- dat_calc_reliablity %>%
dplyr::mutate(Classification_ksm = as.factor(point_ksm),
Classification_oka = as.factor(point_oka)) %>%
dplyr::mutate(ageement = if_else(
Classification_ksm == Classification_oka, 1, 0
)
)
# クロス表の作成
cross_tab_dat <- dat_calc_reliablity %>% group_by(Classification_ksm, Classification_oka) %>%
tally %>%
spread(Classification_oka, n)
#分類一致率の算出
dat_concat_kappa <- dat_calc_reliablity[,c("Classification_ksm", "Classification_oka")]
kappa2(dat_concat_kappa,weight = TRUE)
irr::agree(dat_concat_kappa)
irr::kappam.fleiss(dat_concat_kappa, detail = TRUE)
#最終更新: 2023年5月16日 16:47
library(tidyr)
library(dplyr)
library(lme4)
library(lmerTest)
library(ggplot2)
library(stringr)
library(irr)
library(openxlsx)
#参加者のデータの読み込み
#シート「Sheet 1」の内容
raw_dat <- read.xlsx("../result/20230503_pick_and_classifying_samples_26_percents_format_kusumi.xlsx", sheet = "Sheet 1")
head(raw_dat)
# クロス表の作成
cross_tab_dat <- dat_calc_reliablity %>% group_by(Classification_ksm, Classification_oka) %>%
tally %>%
spread(Classification_oka, n)
#最終更新: 2023年5月16日 16:47
library(tidyr)
library(dplyr)
library(lme4)
library(lmerTest)
library(ggplot2)
library(stringr)
library(irr)
library(openxlsx)
#参加者のデータの読み込み
#シート「Sheet 1」の内容
raw_dat <- read.xlsx("../result/20230503_pick_and_classifying_samples_26_percents_format_kusumi.xlsx", sheet = "Sheet 1")
#dat
dat_calc_reliablity <- raw_dat %>%
dplyr::filter(PickedSample == 1) %>%
dplyr::select(order, trial_index, word_pair, answer, point_oka, point_ksm, comment_oka, Note_ksm)
dat_calc_reliablity <- dat_calc_reliablity %>%
dplyr::mutate(Classification_ksm = as.factor(point_ksm),
Classification_oka = as.factor(point_oka)) %>%
dplyr::mutate(ageement = if_else(
Classification_ksm == Classification_oka, 1, 0
)
)
# クロス表の作成
cross_tab_dat <- dat_calc_reliablity %>% group_by(Classification_ksm, Classification_oka) %>%
tally %>%
spread(Classification_oka, n)
#分類一致率の算出
dat_concat_kappa <- dat_calc_reliablity[,c("Classification_ksm", "Classification_oka")]
kappa2(dat_concat_kappa,weight = TRUE)
irr::agree(dat_concat_kappa)
irr::kappam.fleiss(dat_concat_kappa, detail = TRUE)
setwd("/Users/Ryunosuke/Dropbox/比喩関連/基盤数/metaphor_individual_difference/code/experiment/1_metaphor_individual_difference/Analysis/sst/")
library(tidyr)
library(dplyr)
library(openxlsx)
#結果が再現できるようにseed値を固定する
set.seed(1)
#データの読み込み
raw_dat = read.xlsx("./2_pick_samples_to_calc_reliability/data/MID_EXP1_SST_TARGET_20231225_score_oka_v0.1.xlsx")
#1
trial_index_lst = unique(raw_dat$trial_index)
trial_index_rm_unnnec = trial_index_lst[! trial_index_lst %in% c(0,1,22)]
#得点のベクトルを取得しておく(0,1,2)
#NAもついでに除外する
sh_score_lst = unique(raw_dat$point_oka)
sh_score_lst_rm_unnec = sh_score_lst[!is.na(sh_score_lst)]
sampled_dat = data.frame(
matrix(ncol = length(colnames(raw_dat)),
nrow = 0)
)
colnames(sampled_dat) = colnames(raw_dat)
#質問のsubsetの抽出
sub_trial_index <- raw_dat %>%
dplyr::filter(trial_index == cur_trial_index)
for (cur_trial_index in trial_index_rm_unnnec){
#質問のsubsetの抽出
sub_trial_index <- raw_dat %>%
dplyr::filter(trial_index == cur_trial_index)
#重複を取り除いたsubsetを用意
sub_trial_index_rm_duplicated <- sub_trial_index %>%
dplyr::distinct(answer, .keep_all=TRUE)
#SHごとにサンプルしてくる
#ただし、項目によっては重複で項目数が少なくなることがあるので、
#繰り返しを許して15個ずつ抽出
for (cur_sh_score in sh_score_lst_rm_unnec){
#sh_scoreのsubsetの抽出
sub_sh_score <- sub_trial_index_rm_duplicated %>%
dplyr::filter(point_oka == cur_sh_score)
#ランダムサンプリング
if (cur_sh_score == 0){
#0は少ないので全件抽出
sub_sampled_dat <- sub_trial_index_rm_duplicated %>%
dplyr::filter(point_oka == cur_sh_score)
} else {
#1,2は15件ずつ
sub_sampled_dat = sample_n(tbl = sub_sh_score, size = 15, replace = TRUE)
}
sampled_dat = rbind(sampled_dat, sub_sampled_dat)
}
print(cur_trial_index)
}
sub_trial_index_rm_duplicated
sub_trial_index
sh_score_lst_rm_unnec
cur_sh_score
sub_sh_score
sampled_dat = data.frame(
matrix(ncol = length(colnames(raw_dat)),
nrow = 0)
)
colnames(sampled_dat) = colnames(raw_dat)
for (cur_trial_index in trial_index_rm_unnnec){
#質問のsubsetの抽出
sub_trial_index <- raw_dat %>%
dplyr::filter(trial_index == cur_trial_index)
#重複を取り除いたsubsetを用意
sub_trial_index_rm_duplicated <- sub_trial_index %>%
dplyr::distinct(answer, .keep_all=TRUE)
#SHごとにサンプルしてくる
#ただし、項目によっては重複で項目数が少なくなることがあるので、
#繰り返しを許して15個ずつ抽出
for (cur_sh_score in sh_score_lst_rm_unnec){
#sh_scoreのsubsetの抽出
sub_sh_score <- sub_trial_index_rm_duplicated %>%
dplyr::filter(point_oka == cur_sh_score)
#ランダムサンプリング
if (cur_sh_score == 0){
#0は少ないので全件抽出
sub_sampled_dat <- sub_trial_index_rm_duplicated %>%
dplyr::filter(point_oka == cur_sh_score)
} else {
#1,2は15件ずつ
tryCatch(
{sub_sampled_dat = sample_n(tbl = sub_sh_score, size = 15, replace = TRUE)},
error = function(e){
next
}
)
}
sampled_dat = rbind(sampled_dat, sub_sampled_dat)
}
print(cur_trial_index)
}
sampled_dat = data.frame(
matrix(ncol = length(colnames(raw_dat)),
nrow = 0)
)
colnames(sampled_dat) = colnames(raw_dat)
for (cur_trial_index in trial_index_rm_unnnec){
#質問のsubsetの抽出
sub_trial_index <- raw_dat %>%
dplyr::filter(trial_index == cur_trial_index)
#重複を取り除いたsubsetを用意
sub_trial_index_rm_duplicated <- sub_trial_index %>%
dplyr::distinct(answer, .keep_all=TRUE)
#SHごとにサンプルしてくる
#ただし、項目によっては重複で項目数が少なくなることがあるので、
#繰り返しを許して15個ずつ抽出
for (cur_sh_score in sh_score_lst_rm_unnec){
#sh_scoreのsubsetの抽出
sub_sh_score <- sub_trial_index_rm_duplicated %>%
dplyr::filter(point_oka == cur_sh_score)
#ランダムサンプリング
if (cur_sh_score == 0){
#0は少ないので全件抽出
sub_sampled_dat <- sub_trial_index_rm_duplicated %>%
dplyr::filter(point_oka == cur_sh_score)
sampled_dat = rbind(sampled_dat, sub_sampled_dat)
} else {
#1,2は15件ずつ
tryCatch(
{sub_sampled_dat = sample_n(tbl = sub_sh_score, size = 15, replace = TRUE)
sampled_dat = rbind(sampled_dat, sub_sampled_dat)},
error = function(e){
next
}
)
}
}
print(cur_trial_index)
}
sampled_dat = data.frame(
matrix(ncol = length(colnames(raw_dat)),
nrow = 0)
)
colnames(sampled_dat) = colnames(raw_dat)
for (cur_trial_index in trial_index_rm_unnnec){
#質問のsubsetの抽出
sub_trial_index <- raw_dat %>%
dplyr::filter(trial_index == cur_trial_index)
#重複を取り除いたsubsetを用意
sub_trial_index_rm_duplicated <- sub_trial_index %>%
dplyr::distinct(answer, .keep_all=TRUE)
#SHごとにサンプルしてくる
#ただし、項目によっては重複で項目数が少なくなることがあるので、
#繰り返しを許して15個ずつ抽出
for (cur_sh_score in sh_score_lst_rm_unnec){
#sh_scoreのsubsetの抽出
sub_sh_score <- sub_trial_index_rm_duplicated %>%
dplyr::filter(point_oka == cur_sh_score)
#ランダムサンプリング
if (cur_sh_score == 0){
#0は少ないので全件抽出
sub_sampled_dat <- sub_trial_index_rm_duplicated %>%
dplyr::filter(point_oka == cur_sh_score)
sampled_dat = rbind(sampled_dat, sub_sampled_dat)
} else {
#1,2は15件ずつ
tryCatch(
{sub_sampled_dat = sample_n(tbl = sub_sh_score, size = 15, replace = TRUE)
sampled_dat = rbind(sampled_dat, sub_sampled_dat)},
error = function(e){
message("outch!")
}
)
}
}
print(cur_trial_index)
}
sampled_dat
sampled_dat = data.frame(
matrix(ncol = length(colnames(raw_dat)),
nrow = 0)
)
colnames(sampled_dat) = colnames(raw_dat)
for (cur_trial_index in trial_index_rm_unnnec){
#質問のsubsetの抽出
sub_trial_index <- raw_dat %>%
dplyr::filter(trial_index == cur_trial_index)
#重複を取り除いたsubsetを用意
sub_trial_index_rm_duplicated <- sub_trial_index %>%
dplyr::distinct(answer, .keep_all=TRUE)
#SHごとにサンプルしてくる
#ただし、項目によっては重複で項目数が少なくなることがあるので、
#繰り返しを許して15個ずつ抽出
for (cur_sh_score in sh_score_lst_rm_unnec){
#sh_scoreのsubsetの抽出
sub_sh_score <- sub_trial_index_rm_duplicated %>%
dplyr::filter(point_oka == cur_sh_score)
#ランダムサンプリング
if (cur_sh_score == 0){
#0は少ないので全件抽出
sub_sampled_dat <- sub_trial_index_rm_duplicated %>%
dplyr::filter(point_oka == cur_sh_score)
sampled_dat = rbind(sampled_dat, sub_sampled_dat)
} else {
sub_sampled_dat = sample_n(tbl = sub_sh_score, size = 15, replace = TRUE)
}
}
print(cur_trial_index)
}
sampled_dat = data.frame(
matrix(ncol = length(colnames(raw_dat)),
nrow = 0)
)
colnames(sampled_dat) = colnames(raw_dat)
for (cur_trial_index in trial_index_rm_unnnec){
#質問のsubsetの抽出
sub_trial_index <- raw_dat %>%
dplyr::filter(trial_index == cur_trial_index)
#重複を取り除いたsubsetを用意
sub_trial_index_rm_duplicated <- sub_trial_index %>%
dplyr::distinct(answer, .keep_all=TRUE)
#SHごとにサンプルしてくる
#ただし、項目によっては重複で項目数が少なくなることがあるので、
#繰り返しを許して15個ずつ抽出
for (cur_sh_score in sh_score_lst_rm_unnec){
#sh_scoreのsubsetの抽出
sub_sh_score <- sub_trial_index_rm_duplicated %>%
dplyr::filter(point_oka == cur_sh_score)
#ランダムサンプリング
tryCatch(
{
if (cur_sh_score == 0){
#0は少ないので全件抽出
sub_sampled_dat <- sub_trial_index_rm_duplicated %>%
dplyr::filter(point_oka == cur_sh_score)
} else {
sub_sampled_dat = sample_n(tbl = sub_sh_score, size = 15, replace = TRUE)
}
},
error = function(e){
},
finally = {
sampled_dat = rbind(sampled_dat, sub_sampled_dat)
}
)
}
print(cur_trial_index)
}
sampled_dat
View(sampled_dat)
#ランダム抽出された順番情報を保存
picked_order = sampled_dat$order
#ランダムに抽出したデータを追記したデータフレームを構築
raw_dat$PickedSample = ifelse(raw_dat$order %in% picked_order, 1, 0)
head(raw_dat)
nrow(raw_dat)
nrow(sampled_dat)
nrow(sampled_dat) / nrow(raw_dat)
sampled_dat = data.frame(
matrix(ncol = length(colnames(raw_dat)),
nrow = 0)
)
colnames(sampled_dat) = colnames(raw_dat)
for (cur_trial_index in trial_index_rm_unnnec){
#質問のsubsetの抽出
sub_trial_index <- raw_dat %>%
dplyr::filter(trial_index == cur_trial_index)
#重複を取り除いたsubsetを用意
sub_trial_index_rm_duplicated <- sub_trial_index %>%
dplyr::distinct(answer, .keep_all=TRUE)
#SHごとにサンプルしてくる
#ただし、項目によっては重複で項目数が少なくなることがあるので、
#繰り返しを許して15個ずつ抽出
for (cur_sh_score in sh_score_lst_rm_unnec){
#sh_scoreのsubsetの抽出
sub_sh_score <- sub_trial_index_rm_duplicated %>%
dplyr::filter(point_oka == cur_sh_score)
#ランダムサンプリング
#どっかでひっかかっても無視してつなげる
tryCatch(
{
if (cur_sh_score == 0){
#0は少ないので全件抽出
sub_sampled_dat <- sub_trial_index_rm_duplicated %>%
dplyr::filter(point_oka == cur_sh_score)
} else {
sub_sampled_dat = sample_n(tbl = sub_sh_score, size = 12, replace = TRUE)
}
},
error = function(e){
},
finally = {
sampled_dat = rbind(sampled_dat, sub_sampled_dat)
}
)
}
print(cur_trial_index)
}
#ランダム抽出された順番情報を保存
picked_order = sampled_dat$order
#ランダムに抽出したデータを追記したデータフレームを構築
raw_dat$PickedSample = ifelse(raw_dat$order %in% picked_order, 1, 0)
head(raw_dat)
nrow(sampled_dat) / nrow(raw_dat)
View(sampled_dt)
View(sampled_dat)
View(sampled_dat)
setwd("/Users/Ryunosuke/Dropbox/比喩関連/基盤数/metaphor_individual_difference/code/experiment/1_metaphor_individual_difference/Analysis/sst/")
library(tidyr)
library(dplyr)
library(openxlsx)
#結果が再現できるようにseed値を固定する
set.seed(1)
#データの読み込み
raw_dat = read.xlsx("./2_pick_samples_to_calc_reliability/data/MID_EXP1_SST_TARGET_20231225_score_oka_v0.1.xlsx")
#1
trial_index_lst = unique(raw_dat$trial_index)
trial_index_rm_unnnec = trial_index_lst[! trial_index_lst %in% c(0,1,22)]
#得点のベクトルを取得しておく(0,1,2)
#NAもついでに除外する
sh_score_lst = unique(raw_dat$point_oka)
sh_score_lst_rm_unnec = sh_score_lst[!is.na(sh_score_lst)]
sampled_dat = data.frame(
matrix(ncol = length(colnames(raw_dat)),
nrow = 0)
)
colnames(sampled_dat) = colnames(raw_dat)
for (cur_trial_index in trial_index_rm_unnnec){
#質問のsubsetの抽出
sub_trial_index <- raw_dat %>%
dplyr::filter(trial_index == cur_trial_index)
#重複を取り除いたsubsetを用意
sub_trial_index_rm_duplicated <- sub_trial_index %>%
dplyr::distinct(answer, .keep_all=TRUE)
#SHごとにサンプルしてくる
#ただし、項目によっては重複で項目数が少なくなることがあるので、
#繰り返しを許して10個ずつ抽出
for (cur_sh_score in sh_score_lst_rm_unnec){
#sh_scoreのsubsetの抽出
sub_sh_score <- sub_trial_index_rm_duplicated %>%
dplyr::filter(point_oka == cur_sh_score)
#ランダムサンプリング
#どっかでひっかかっても無視してつなげる
tryCatch(
{
if (cur_sh_score == 0){
#0は少ないので全件抽出
sub_sampled_dat <- sub_trial_index_rm_duplicated %>%
dplyr::filter(point_oka == cur_sh_score)
} else {
sub_sampled_dat = sample_n(tbl = sub_sh_score, size = 10, replace = TRUE)
}
},
error = function(e){
},
finally = {
sampled_dat = rbind(sampled_dat, sub_sampled_dat)
}
)
}
print(cur_trial_index)
}
#ランダム抽出された順番情報を保存
picked_order = sampled_dat$order
#ランダムに抽出したデータを追記したデータフレームを構築
raw_dat$PickedSample = ifelse(raw_dat$order %in% picked_order, 1, 0)
head(raw_dat)
View(sampled_dat)
nrow(sampled_dat)/nrow(raw_dat)
nrow(sampled_dat)
#重複を覗くと498件が残る(498/1955 = 25%)ので、それを出力
#抽出したデータを吐き出す
openxlsx::write.xlsx(raw_dat, "./2_pick_samples_to_calc_reliability/task/20231227_pick_and_classifying_samples_25_percents.xlsx")
423/1955
